# -*- coding: utf-8 -*-
"""Copy of BUSII.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18xp247_yAYflEdH9kxRk85Mbt4UsoIdP
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install -q tensorflow matplotlib scikit-learn seaborn

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2, EfficientNetB0
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# Change this path if needed
dataset_path = "/content/drive/MyDrive/Dataset_BUSI_with_GT"

img_size = (224, 224)
batch_size = 32

# Data augmentation
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    zoom_range=0.2,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

class_names = list(train_generator.class_indices.keys())
num_classes = len(class_names)

"""# Augmentation"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img
import os
from pathlib import Path

#  Set your existing paths
RAW_DATA_DIR = "/content/drive/MyDrive/Dataset_BUSI_with_GT"
AUG_DATA_DIR = "/content/drive/MyDrive/BUSI_augmented"

#  Augmentor setup
augmentor = ImageDataGenerator(
    rotation_range=15,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

#  Augment each image 2 times
def augment_class_images(class_name, augment_count=2):
    input_path = os.path.join(RAW_DATA_DIR, class_name)
    output_path = os.path.join(AUG_DATA_DIR, class_name)
    os.makedirs(output_path, exist_ok=True)

    image_paths = list(Path(input_path).glob("*.jpg")) + list(Path(input_path).glob("*.png"))

    for img_path in image_paths:
        img = load_img(img_path)
        x = img_to_array(img).reshape((1,) + img.size[::-1] + (3,))
        base_name = Path(img_path).stem
        for i, batch in enumerate(augmentor.flow(x, batch_size=1)):
            save_img(os.path.join(output_path, f"{base_name}_aug{i}.jpg"), batch[0])
            if i + 1 >= augment_count:
                break
        print(f" {base_name} -> {augment_count} augmentations in '{class_name}'")

#  Run for each class
for cls in ["benign", "malignant", "normal"]:  # remove "normal" if not present
    if os.path.exists(os.path.join(RAW_DATA_DIR, cls)):
        augment_class_images(cls, augment_count=2)

import os

# Dataset path
dataset_path = "/content/drive/MyDrive/BUSI_augmented"
img_size = (224, 224)
batch_size = 32
num_classes = 3

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Only rescale now, no further augmentation
data_gen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2  # 80% training, 20% validation
)

train_generator = data_gen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

val_generator = data_gen.flow_from_directory(
    dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=False,
    seed=42
)

class_names = list(train_generator.class_indices.keys())
print(" Classes found:", class_names)

"""# ABER Optimizer"""

import random
import numpy as np

def aber_optimize(fitness_function, bounds, n_agents=5, max_iter=5):

    # Initialize agents randomly
    population = []
    for _ in range(n_agents):
        agent = [random.uniform(b[0], b[1]) for b in bounds]
        population.append(agent)

    best_solution = None
    best_score = -np.inf

    for iteration in range(max_iter):
        print(f"\n ABER Iteration {iteration + 1}/{max_iter}")
        new_population = []

        for i, agent in enumerate(population):
            # Mutate one of the parameters (exploration)
            new_agent = agent.copy()
            param_to_mutate = random.randint(0, len(bounds) - 1)
            new_agent[param_to_mutate] = random.uniform(bounds[param_to_mutate][0], bounds[param_to_mutate][1])

            # Evaluate both original and mutated
            score_old = fitness_function(agent)
            score_new = fitness_function(new_agent)

            # Keep the better one
            if score_new > score_old:
                new_population.append(new_agent)
                if score_new > best_score:
                    best_score = score_new
                    best_solution = new_agent
                print(f" Agent {i+1} improved ‚Üí Acc: {score_new:.4f}")
            else:
                new_population.append(agent)
                if score_old > best_score:
                    best_score = score_old
                    best_solution = agent
                print(f" Agent {i+1} retained ‚Üí Acc: {score_old:.4f}")

        population = new_population

    print("\n ABER Optimization Finished!")
    return best_solution, best_score

# BUSI dataset
img_size = (224, 224)
batch_size = 32
num_classes = 3
dataset_path = "/content/drive/MyDrive/BUSI_augmented"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = data_gen.flow_from_directory(
    dataset_path, target_size=img_size, batch_size=batch_size,
    class_mode='categorical', subset='training', shuffle=True, seed=42
)

val_generator = data_gen.flow_from_directory(
    dataset_path, target_size=img_size, batch_size=batch_size,
    class_mode='categorical', subset='validation', shuffle=False, seed=42
)

class_names = list(train_generator.class_indices.keys())

def evaluate_model_with_params(params, base_model_fn, train_gen, val_gen):
    lr, dropout, dense_units = params

    base_model = base_model_fn(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
    base_model.trainable = False

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dropout(float(dropout))(x)
    x = Dense(int(dense_units), activation='relu')(x)
    x = Dropout(float(dropout))(x)
    output = Dense(train_gen.num_classes, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=output)

    model.compile(optimizer=Adam(learning_rate=float(lr)),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    # ‚ö° Reduced time
    history = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=1,  # ‚ö° One epoch only
        steps_per_epoch=min(10, len(train_gen)),
        validation_steps=min(5, len(val_gen)),
        verbose=0
    )

    return history.history['val_accuracy'][-1]

"""# VGG16 ABER"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

print("\n Running ABER Optimization for VGG16...")

bounds = [(1e-5, 1e-3), (0.2, 0.5), (64, 256)]

best_params_vgg16, best_acc_vgg16 = aber_optimize(
    lambda params: evaluate_model_with_params(params, VGG16, train_generator, val_generator),
    bounds,
    n_agents=3,
    max_iter=3
)

print(f"\n VGG16 ABER ‚Üí LR: {best_params_vgg16[0]:.6f}, Dropout: {best_params_vgg16[1]:.2f}, Units: {int(best_params_vgg16[2])}, Acc: {best_acc_vgg16:.4f}")

"""# ABER for ResNet50"""

from tensorflow.keras.applications import ResNet50

print("\n Running ABER Optimization for ResNet50...")
bounds = [(1e-5, 1e-3), (0.2, 0.5), (64, 256)]


best_params_resnet50, best_acc_resnet50 = aber_optimize(
    lambda params: evaluate_model_with_params(params, ResNet50, train_generator, val_generator),
    bounds,
    n_agents=3,
    max_iter=3
)

print(f"\n ResNet50 ABER ‚Üí LR: {best_params_resnet50[0]:.6f}, Dropout: {best_params_resnet50[1]:.2f}, Units: {int(best_params_resnet50[2])}, Acc: {best_acc_resnet50:.4f}")

"""# ABER for MobileNetV2"""

from tensorflow.keras.applications import MobileNetV2

print("\nüîç Running ABER Optimization for MobileNetV2...")
bounds = [(1e-5, 1e-3), (0.2, 0.5), (64, 256)]

best_params_mobilenetv2, best_acc_mobilenetv2 = aber_optimize(
    lambda params: evaluate_model_with_params(params, MobileNetV2, train_generator, val_generator),
    bounds,
    n_agents=3,
    max_iter=3
)

print(f"\n‚úÖ MobileNetV2 ABER ‚Üí LR: {best_params_mobilenetv2[0]:.6f}, Dropout: {best_params_mobilenetv2[1]:.2f}, Units: {int(best_params_mobilenetv2[2])}, Acc: {best_acc_mobilenetv2:.4f}")

"""# ABER for EfficientNetB0"""

from tensorflow.keras.applications import EfficientNetB0

print("\nüîç Running ABER Optimization for EfficientNetB0...")
bounds = [(1e-5, 1e-3), (0.2, 0.5), (64, 256)]

best_params_effnet, best_acc_effnet = aber_optimize(
    lambda params: evaluate_model_with_params(params, EfficientNetB0, train_generator, val_generator),
    bounds,
    n_agents=3,
    max_iter=3
)

print(f"\n‚úÖ EfficientNetB0 ABER ‚Üí LR: {best_params_effnet[0]:.6f}, Dropout: {best_params_effnet[1]:.2f}, Units: {int(best_params_effnet[2])}, Acc: {best_acc_effnet:.4f}")

# Dictionary of final ABER-optimized validation accuracies
aber_model_accuracies = {
    "VGG16_ABER": 1.0000,
    "ResNet50_ABER": 1.0000,
    "MobileNetV2_ABER": 1.0000,
    "EfficientNetB0_ABER": 1.0000
}

# Find the best model
best_model = max(aber_model_accuracies, key=aber_model_accuracies.get)
best_accuracy = aber_model_accuracies[best_model]

print(" Best ABER-Optimized Model:")
print(f" Model Name: {best_model}")
print(f" Validation Accuracy: {best_accuracy:.4f}")

import matplotlib.pyplot as plt

# Plot
plt.figure(figsize=(8, 5))
plt.bar(aber_model_accuracies.keys(), aber_model_accuracies.values(), color='skyblue')
plt.ylim(0.9, 1.01)
plt.ylabel("Validation Accuracy")
plt.title("ABER-Optimized Model Accuracy Comparison")
plt.xticks(rotation=20)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""# Save Models

# vgg16
"""

import os
from PIL import Image

def remove_corrupt_images(folder_path):
    removed = 0
    for root, _, files in os.walk(folder_path):
        for file in files:
            file_path = os.path.join(root, file)
            try:
                img = Image.open(file_path)
                img.verify()  # Verify if image can be opened
            except (IOError, SyntaxError, Image.DecompressionBombError):
                print(f" Removing corrupt image: {file_path}")
                os.remove(file_path)
                removed += 1
    print(f" Done. Total corrupt images removed: {removed}")

# Example:
remove_corrupt_images("/content/drive/MyDrive/BUSI_augmented")

import os

def list_non_images(folder):
    for root, _, files in os.walk(folder):
        for file in files:
            if not file.lower().endswith(('.jpg', '.jpeg', '.png')):
                print(f" Not an image: {os.path.join(root, file)}")

list_non_images("/content/drive/MyDrive/BUSI_augmented")

import time
import matplotlib.pyplot as plt
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.optimizers import Adam

#  Start time
start_time = time.time()

# Build model
base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base.trainable = False

x = GlobalAveragePooling2D()(base.output)
x = Dropout(0.39)(x)
x = Dense(238, activation='relu')(x)
x = Dropout(0.39)(x)
output = Dense(3, activation='softmax')(x)

vgg16_model = Model(inputs=base.input, outputs=output)
vgg16_model.compile(optimizer=Adam(learning_rate=0.000408), loss='categorical_crossentropy', metrics=['accuracy'])

#  Train model & save history
history_vgg16 = vgg16_model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15
)

#  End time
end_time = time.time()

#  Save model
vgg16_model.save("/content/drive/MyDrive/Final_ABER_Models/VGG16_ABER_Optimized.keras")

#  Plot accuracy & loss
plt.plot(history_vgg16.history['accuracy'], label='Train Acc')
plt.plot(history_vgg16.history['val_accuracy'], label='Val Acc')
plt.plot(history_vgg16.history['loss'], label='Train Loss')
plt.plot(history_vgg16.history['val_loss'], label='Val Loss')
plt.title("VGG16 ABER - Accuracy & Loss")
plt.xlabel("Epochs")
plt.ylabel("Value")
plt.legend()
plt.grid(True)
plt.show()

#  Final accuracy
train_acc = history_vgg16.history['accuracy'][-1]
val_acc = history_vgg16.history['val_accuracy'][-1]

print(f" VGG16_ABER - Train Accuracy: {train_acc:.4f}")
print(f" VGG16_ABER - Val Accuracy:   {val_acc:.4f}")
print(f" Time Taken: {(end_time - start_time)/60:.2f} minutes")

"""# resnet50"""

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import time

# Build model
base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base.trainable = False
x = GlobalAveragePooling2D()(base.output)
x = Dropout(0.47)(x)
x = Dense(238, activation='relu')(x)
x = Dropout(0.47)(x)
output = Dense(3, activation='softmax')(x)

resnet50_model = Model(inputs=base.input, outputs=output)
resnet50_model.compile(optimizer=Adam(learning_rate=0.000408), loss='categorical_crossentropy', metrics=['accuracy'])

# Train and track time
start_time = time.time()
history_resnet50 = resnet50_model.fit(train_generator, validation_data=val_generator, epochs=15)
end_time = time.time()

# Save model
resnet50_model.save("/content/drive/MyDrive/Final_ABER_Models/ResNet50_ABER_Optimized.keras")

# Plot
plt.plot(history_resnet50.history['accuracy'], label='Train Acc')
plt.plot(history_resnet50.history['val_accuracy'], label='Val Acc')
plt.plot(history_resnet50.history['loss'], label='Train Loss')
plt.plot(history_resnet50.history['val_loss'], label='Val Loss')
plt.title('ResNet50 Training History')
plt.xlabel('Epochs')
plt.ylabel('Accuracy / Loss')
plt.legend()
plt.grid(True)
plt.show()

# Accuracy report
print(f" ResNet50 Training Accuracy: {history_resnet50.history['accuracy'][-1]:.4f}")
print(f" ResNet50 Validation Accuracy: {history_resnet50.history['val_accuracy'][-1]:.4f}")
print(f" Training Time: {end_time - start_time:.2f} seconds")

"""# mobilenet"""

from tensorflow.keras.applications import MobileNetV2

# Build model
base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base.trainable = False
x = GlobalAveragePooling2D()(base.output)
x = Dropout(0.44)(x)
x = Dense(124, activation='relu')(x)
x = Dropout(0.44)(x)
output = Dense(3, activation='softmax')(x)

mobilenet_model = Model(inputs=base.input, outputs=output)
mobilenet_model.compile(optimizer=Adam(learning_rate=0.000640), loss='categorical_crossentropy', metrics=['accuracy'])

# Train and track time
start_time = time.time()
history_mobilenet = mobilenet_model.fit(train_generator, validation_data=val_generator, epochs=15)
end_time = time.time()

# Save model
mobilenet_model.save("/content/drive/MyDrive/Final_ABER_Models/MobileNetV2_ABER_Optimized.keras")

# Plot
plt.plot(history_mobilenet.history['accuracy'], label='Train Acc')
plt.plot(history_mobilenet.history['val_accuracy'], label='Val Acc')
plt.plot(history_mobilenet.history['loss'], label='Train Loss')
plt.plot(history_mobilenet.history['val_loss'], label='Val Loss')
plt.title('MobileNetV2 Training History')
plt.xlabel('Epochs')
plt.ylabel('Accuracy / Loss')
plt.legend()
plt.grid(True)
plt.show()

# Accuracy report
print(f" MobileNetV2 Training Accuracy: {history_mobilenet.history['accuracy'][-1]:.4f}")
print(f" MobileNetV2 Validation Accuracy: {history_mobilenet.history['val_accuracy'][-1]:.4f}")
print(f" Training Time: {end_time - start_time:.2f} seconds")

"""# efficientnet"""

from tensorflow.keras.applications import EfficientNetB0

# Build model
base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base.trainable = False
x = GlobalAveragePooling2D()(base.output)
x = Dropout(0.38)(x)
x = Dense(181, activation='relu')(x)
x = Dropout(0.38)(x)
output = Dense(3, activation='softmax')(x)

efficientnet_model = Model(inputs=base.input, outputs=output)
efficientnet_model.compile(optimizer=Adam(learning_rate=0.000159), loss='categorical_crossentropy', metrics=['accuracy'])

# Train and track time
start_time = time.time()
history_efficientnet = efficientnet_model.fit(train_generator, validation_data=val_generator, epochs=15)
end_time = time.time()

# Save model
efficientnet_model.save("/content/drive/MyDrive/Final_ABER_Models/EfficientNetB0_ABER_Optimized.keras")

# Plot
plt.plot(history_efficientnet.history['accuracy'], label='Train Acc')
plt.plot(history_efficientnet.history['val_accuracy'], label='Val Acc')
plt.plot(history_efficientnet.history['loss'], label='Train Loss')
plt.plot(history_efficientnet.history['val_loss'], label='Val Loss')
plt.title('EfficientNetB0 Training History')
plt.xlabel('Epochs')
plt.ylabel('Accuracy / Loss')
plt.legend()
plt.grid(True)
plt.show()

# Accuracy report
print(f" EfficientNetB0 Training Accuracy: {history_efficientnet.history['accuracy'][-1]:.4f}")
print(f" EfficientNetB0 Validation Accuracy: {history_efficientnet.history['val_accuracy'][-1]:.4f}")
print(f" Training Time: {end_time - start_time:.2f} seconds")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Load class names from your val_generator
class_names = list(val_generator.class_indices.keys())

def evaluate_aber_model(model_path, model_name):
    model = load_model(model_path)

    # Predict
    val_generator.reset()
    y_probs = model.predict(val_generator)
    y_preds = np.argmax(y_probs, axis=1)
    y_true = val_generator.classes

    # Accuracy
    acc = np.mean(y_preds == y_true)
    print(f"\n {model_name} Accuracy: {acc:.4f}")

    # Classification report
    print(f"\n Classification Report for {model_name}:")
    print(classification_report(y_true, y_preds, target_names=class_names))

    # Confusion matrix
    cm = confusion_matrix(y_true, y_preds)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
    plt.title(f"{model_name} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

    # ROC AUC (multi-class)
    try:
        auc = roc_auc_score(val_generator.labels, y_probs, multi_class='ovr')
        print(f" ROC AUC Score: {auc:.4f}")
    except Exception as e:
        print(" ROC AUC could not be computed:", e)

    return acc

model_paths = {
    "VGG16_ABER": "/content/drive/MyDrive/Final_ABER_Models/VGG16_ABER_Optimized.keras",
    "ResNet50_ABER": "/content/drive/MyDrive/Final_ABER_Models/ResNet50_ABER_Optimized.keras",
    "MobileNetV2_ABER": "/content/drive/MyDrive/Final_ABER_Models/MobileNetV2_ABER_Optimized.keras",
    "EfficientNetB0_ABER": "/content/drive/MyDrive/Final_ABER_Models/EfficientNetB0_ABER_Optimized.keras"
}

aber_model_accuracies = {}

for name, path in model_paths.items():
    print(f" Evaluating: {name}")
    acc = evaluate_aber_model(path, name)
    aber_model_accuracies[name] = acc

import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import load_model

#  Step 1: Define model names and paths
model_info = {
    "VGG16_ABER": "/content/drive/MyDrive/Final_ABER_Models/VGG16_ABER_Optimized.keras",
    "ResNet50_ABER": "/content/drive/MyDrive/Final_ABER_Models/ResNet50_ABER_Optimized.keras",
    "MobileNetV2_ABER": "/content/drive/MyDrive/Final_ABER_Models/MobileNetV2_ABER_Optimized.keras",
    "EfficientNetB0_ABER": "/content/drive/MyDrive/Final_ABER_Models/EfficientNetB0_ABER_Optimized.keras"
}

# Step 2: Evaluate models on validation data
model_names = []
accuracies = []

for name, path in model_info.items():
    print(f" Evaluating: {name}")
    model = load_model(path)
    loss, acc = model.evaluate(val_generator, verbose=0)
    print(f" {name} Accuracy: {acc:.4f}")
    model_names.append(name)
    accuracies.append(acc)

#  Step 3: Plot Accuracy Comparison
plt.figure(figsize=(10, 6))
bars = plt.bar(model_names, accuracies, color='skyblue')

# Add accuracy values on top
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f"{yval:.2f}", ha='center', fontsize=10)

plt.title("ABER-Optimized Model Comparison")
plt.ylabel("Validation Accuracy")
plt.ylim(0.65, 0.95)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import load_model
from sklearn.metrics import roc_auc_score
from tensorflow.keras.utils import to_categorical

# Define model paths
model_info = {
    "VGG16_ABER": "/content/drive/MyDrive/Final_ABER_Models/VGG16_ABER_Optimized.keras",
    "ResNet50_ABER": "/content/drive/MyDrive/Final_ABER_Models/ResNet50_ABER_Optimized.keras",
    "MobileNetV2_ABER": "/content/drive/MyDrive/Final_ABER_Models/MobileNetV2_ABER_Optimized.keras",
    "EfficientNetB0_ABER": "/content/drive/MyDrive/Final_ABER_Models/EfficientNetB0_ABER_Optimized.keras"
}

# Setup to store results
model_names = []
accuracies = []
roc_aucs = []

# True labels
val_generator.reset()
y_true = val_generator.classes
y_true_cat = to_categorical(y_true, num_classes=3)

#  Loop through each model and compute metrics
for name, path in model_info.items():
    print(f" Evaluating: {name}")
    model = load_model(path)

    # Accuracy
    loss, acc = model.evaluate(val_generator, verbose=0)
    accuracies.append(acc)

    # ROC-AUC
    val_generator.reset()
    y_probs = model.predict(val_generator)
    roc_auc = roc_auc_score(y_true_cat, y_probs, multi_class='ovr')
    roc_aucs.append(roc_auc)

    model_names.append(name)
    print(f" {name} ‚Üí Accuracy: {acc:.4f}, ROC-AUC: {roc_auc:.4f}")

#  Plot Accuracy vs. ROC-AUC
x = np.arange(len(model_names))
width = 0.35

plt.figure(figsize=(10, 6))
bar1 = plt.bar(x - width/2, accuracies, width, label='Accuracy', color='skyblue')
bar2 = plt.bar(x + width/2, roc_aucs, width, label='ROC-AUC', color='salmon')

# Annotate bars
for bar in bar1 + bar2:
    height = bar.get_height()
    plt.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width() / 2, height),
                 xytext=(0, 3), textcoords="offset points", ha='center', fontsize=9)

plt.xticks(x, model_names, rotation=15)
plt.ylim(0.5, 1.05)
plt.ylabel("Score")
plt.title("ABER-Optimized Model Accuracy vs. ROC-AUC")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

#  Define model paths
model_info = {
    "VGG16_ABER": "/content/drive/MyDrive/Final_ABER_Models/VGG16_ABER_Optimized.keras",
    "ResNet50_ABER": "/content/drive/MyDrive/Final_ABER_Models/ResNet50_ABER_Optimized.keras",
    "MobileNetV2_ABER": "/content/drive/MyDrive/Final_ABER_Models/MobileNetV2_ABER_Optimized.keras",
    "EfficientNetB0_ABER": "/content/drive/MyDrive/Final_ABER_Models/EfficientNetB0_ABER_Optimized.keras"
}

#  Lists to store results
model_names = []
val_losses = []

#  Loop to evaluate losses
for name, path in model_info.items():
    print(f" Evaluating loss for: {name}")
    model = load_model(path)
    loss, acc = model.evaluate(val_generator, verbose=0)
    model_names.append(name)
    val_losses.append(loss)
    print(f" {name} ‚Üí Validation Loss: {loss:.4f}")

#  Plotting the loss comparison
plt.figure(figsize=(10, 6))
bars = plt.bar(model_names, val_losses, color='salmon')

# Add loss values on top of bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f"{yval:.4f}", ha='center', fontsize=10)

plt.title("ABER-Optimized Model Validation Loss Comparison")
plt.ylabel("Validation Loss")
plt.ylim(min(val_losses) - 0.05, max(val_losses) + 0.1)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""# Predictions"""

from tensorflow.keras.models import load_model

vgg16_model = load_model("/content/drive/MyDrive/Final_ABER_Models/VGG16_ABER_Optimized.keras")
resnet50_model = load_model("/content/drive/MyDrive/Final_ABER_Models/ResNet50_ABER_Optimized.keras")
mobilenet_model = load_model("/content/drive/MyDrive/Final_ABER_Models/MobileNetV2_ABER_Optimized.keras")
efficientnet_model = load_model("/content/drive/MyDrive/Final_ABER_Models/EfficientNetB0_ABER_Optimized.keras")

import numpy as np
from tensorflow.keras.preprocessing import image


img_path = "/content/drive/MyDrive/BUSI_augmented/benign/benign (1)_aug4.jpg"

img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array /= 255.0

class_names = ['benign', 'malignant', 'normal']

# Predict from each model
pred_vgg16 = vgg16_model.predict(img_array)
pred_resnet = resnet50_model.predict(img_array)
pred_mobilenet = mobilenet_model.predict(img_array)
pred_efficientnet = efficientnet_model.predict(img_array)

# Decode predictions
print(" Prediction Results:\n")

print(" VGG16 Prediction:", class_names[np.argmax(pred_vgg16)], "‚Üí Prob:", np.max(pred_vgg16).round(4))
print(" ResNet50 Prediction:", class_names[np.argmax(pred_resnet)], "‚Üí Prob:", np.max(pred_resnet).round(4))
print(" MobileNetV2 Prediction:", class_names[np.argmax(pred_mobilenet)], "‚Üí Prob:", np.max(pred_mobilenet).round(4))
print(" EfficientNetB0 Prediction:", class_names[np.argmax(pred_efficientnet)], "‚Üí Prob:", np.max(pred_efficientnet).round(4))

img_path = "/content/drive/MyDrive/BUSI_augmented/normal/normal (100)_mask_aug0.jpg"

img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array /= 255.0

class_names = ['benign', 'malignant', 'normal']

# Predict from each model
pred_vgg16 = vgg16_model.predict(img_array)
pred_resnet = resnet50_model.predict(img_array)
pred_mobilenet = mobilenet_model.predict(img_array)
pred_efficientnet = efficientnet_model.predict(img_array)

# Decode predictions
print(" Prediction Results:\n")

print(" VGG16 Prediction:", class_names[np.argmax(pred_vgg16)], "‚Üí Prob:", np.max(pred_vgg16).round(4))
print(" ResNet50 Prediction:", class_names[np.argmax(pred_resnet)], "‚Üí Prob:", np.max(pred_resnet).round(4))
print(" MobileNetV2 Prediction:", class_names[np.argmax(pred_mobilenet)], "‚Üí Prob:", np.max(pred_mobilenet).round(4))
print(" EfficientNetB0 Prediction:", class_names[np.argmax(pred_efficientnet)], "‚Üí Prob:", np.max(pred_efficientnet).round(4))

img_path = "/content/drive/MyDrive/BUSI_augmented/malignant/malignant (103)_mask_aug1.jpg"

img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array /= 255.0

class_names = ['benign', 'malignant', 'normal']

# Predict from each model
pred_vgg16 = vgg16_model.predict(img_array)
pred_resnet = resnet50_model.predict(img_array)
pred_mobilenet = mobilenet_model.predict(img_array)
pred_efficientnet = efficientnet_model.predict(img_array)

# Decode predictions
print(" Prediction Results:\n")

print(" VGG16 Prediction:", class_names[np.argmax(pred_vgg16)], "‚Üí Prob:", np.max(pred_vgg16).round(4))
print(" ResNet50 Prediction:", class_names[np.argmax(pred_resnet)], "‚Üí Prob:", np.max(pred_resnet).round(4))
print(" MobileNetV2 Prediction:", class_names[np.argmax(pred_mobilenet)], "‚Üí Prob:", np.max(pred_mobilenet).round(4))
print(" EfficientNetB0 Prediction:", class_names[np.argmax(pred_efficientnet)], "‚Üí Prob:", np.max(pred_efficientnet).round(4))



